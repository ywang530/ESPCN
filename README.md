# Efficient Sub-Pixel Convolutional Neural Network (ESPCN)
 A PyTorch reimplementation of ESPCN based on paper [***Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network***](https://arxiv.org/abs/1609.05158)

## Requirements
- Pytorch
- Anaconda

## Datasets
The dataset I used to train and validate the model is VOC2012 (Pascal VOC challenge). The dataset contains 17,125 images of 20 objects: person, bird, cat, cow, dog, horse, sheep, airplane, bicycle, boat, bus, car, motorbike, train, bottle, chair, dining table, potted plant, sofa, tv/monitor. 

75% of the images, 12,844, are partitioned to be training set, and 25% of the images, 4,281, are partitioned to be validation set. 

To generate the LR input images, I downsampled the imaged corresponding to different upscale factors. For this project, I tested upscale factor from 2 to 8. The model is tested on Set 5 (5 images), Set 14 (14 images), and CelebA (first 30 images) datasets.

## Implementation
The model used to conduct this project contains 3 layers: 
- ğ¹ğ‘–ğ‘Ÿğ‘ ğ‘¡ ğ»ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘› ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ: ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ¼ğ‘›=1,ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ‘‚ğ‘¢ğ‘¡=64,ğ¾ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ ğ‘ ğ‘–ğ‘§ğ‘’=5 
- ğ‘†ğ‘’ğ‘ğ‘œğ‘›ğ‘‘ ğ»ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘› ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ: ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ¼ğ‘›=64,ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ‘‚ğ‘¢ğ‘¡=32,ğ¾ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ ğ‘ ğ‘–ğ‘§ğ‘’=3 
- ğ‘‡â„ğ‘–ğ‘Ÿğ‘‘ ğ»ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘› ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ: ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ¼ğ‘›=32,ğ¶â„ğ‘ğ‘›ğ‘›ğ‘’ğ‘™ ğ‘‚ğ‘¢ğ‘¡ =ğ‘ˆğ‘ğ‘ ğ‘ğ‘ğ‘™ğ‘’ ğ¹ğ‘ğ‘ğ‘¡ğ‘œğ‘Ÿ2, ğ¾ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘™ ğ‘ ğ‘–ğ‘§ğ‘’=3

The reason why the input channel is 1 is that the color space used here is YCbCr and only Y channel is considered and processed as human eyes are more sensitive to luminance.
First two Hidden Layers are followed by Tanh activation function, while the last one is followed by Pixel Shuffle (sub-pixel convolution) which rearranges the elements in of shape (âˆ—, ğ¶Ã—ğ‘Ÿ2, ğ», ğ‘Š) to shape (âˆ—, ğ¶, ğ»Ã— ğ‘Ÿ, ğ‘ŠÃ— ğ‘Ÿ).

The Loss Function used is pixel-wise mean squared error (MSE) and the Optimizer used is Adam optimizer. The initial learning rate is set to 1ğ‘’âˆ’2, and will decrease to 1ğ‘’âˆ’3 after epochs 15 then decrease to 1ğ‘’âˆ’4 after epochs 80. For the experiment, the total Epoch is set to be 100.

To evaluate the performance of the model, I used PSNR in dB as a metric to compare with commonly used bicubic interpolation:

<a href="https://www.codecogs.com/eqnedit.php?latex=PSNR&space;=&space;10\times&space;\log_{10}\frac{1}{MSE}" target="_blank"><img src="https://latex.codecogs.com/svg.latex?PSNR&space;=&space;10\times&space;\log_{10}\frac{1}{MSE}" title="PSNR = 10\times \log_{10}\frac{1}{MSE}" /></a>

##  Results Comparison 
